{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7965c0-943c-4cca-9e49-4ece40d753cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")  # Use the appropriate model variant (e.g., yolov8s.pt for higher accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6fa6b63-79f1-4491-bb8d-982187305b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define traffic signal states\n",
    "signal_states = [\"NORTH-SOUTH\", \"EAST-WEST\"]\n",
    "\n",
    "# Initialize variables\n",
    "signal_duration = 10  # seconds for each signal state\n",
    "vehicle_classes = [2, 3, 5, 7]  # YOLO class IDs for car, motorcycle, bus, truck\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9795de58-72dc-480d-80a3-d427e591bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, model):\n",
    "   \n",
    "    height, width, _ = frame.shape\n",
    "    \n",
    "    # Define regions for each side of the intersection\n",
    "    regions = {\n",
    "        \"NORTH\": [(0, 0), (width, height // 4)],\n",
    "        \"SOUTH\": [(0, 3 * height // 4), (width, height)],\n",
    "        \"EAST\": [(3 * width // 4, 0), (width, height)],\n",
    "        \"WEST\": [(0, 0), (width // 4, height)],\n",
    "    }\n",
    "    \n",
    "    vehicle_counts = {side: 0 for side in regions}\n",
    "    \n",
    "    # Perform object detection\n",
    "    results = model(frame, verbose=False)\n",
    "    detections = results[0].boxes.boxes.cpu().numpy()  # Extract detections as numpy array\n",
    "    \n",
    "    for detection in detections:\n",
    "        x1, y1, x2, y2, confidence, class_id = detection\n",
    "        if int(class_id) in vehicle_classes:\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2  # Calculate center of the bounding box\n",
    "            \n",
    "            # Determine which region the vehicle is in\n",
    "            for side, ((x_start, y_start), (x_end, y_end)) in regions.items():\n",
    "                if x_start <= cx <= x_end and y_start <= cy <= y_end:\n",
    "                    vehicle_counts[side] += 1\n",
    "                    break\n",
    "\n",
    "    return vehicle_counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faee2cdb-c6f5-43ae-9288-3f73945ad079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_signal(vehicle_counts):\n",
    "   \n",
    "    north_south = vehicle_counts[\"NORTH\"] + vehicle_counts[\"SOUTH\"]\n",
    "    east_west = vehicle_counts[\"EAST\"] + vehicle_counts[\"WEST\"]\n",
    "    \n",
    "    if north_south >= east_west:\n",
    "        return \"NORTH-SOUTH\"\n",
    "    else:\n",
    "        return \"EAST-WEST\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab77104-b305-4e1e-b7c5-d029b885634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(video_path):\n",
    "    # Open video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    current_signal = \"NORTH-SOUTH\"\n",
    "    last_switch_time = time.time()\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (640, 640))  # Resize to 640x640 for faster processing\n",
    "        # Resize frame for consistent processing\n",
    "        frame = cv2.resize(frame, (640, 640))\n",
    "        \n",
    "        # Process the frame to count vehicles\n",
    "        vehicle_counts = process_frame(frame, model)\n",
    "        print(f\"Vehicle counts: {vehicle_counts}\")\n",
    "        \n",
    "        # Decide signal state based on vehicle counts\n",
    "        if time.time() - last_switch_time > signal_duration:\n",
    "            current_signal = decide_signal(vehicle_counts)\n",
    "            last_switch_time = time.time()\n",
    "        \n",
    "        # Display current signal state\n",
    "        cv2.putText(frame, f\"Current Signal: {current_signal}\", (10, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # Show the frame\n",
    "        cv2.imshow(\"Traffic Control\", frame)\n",
    "        \n",
    "        # Exit on pressing 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run the program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1f9cac-c27a-40bf-8445-dd6dd7fbf220",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    video_path = r\"C:\\Users\\ashri\\Documents\\Ash\\DSU\\SEM 5\\AIML\\MINI project\\video1.mp4\"\n",
    "    main(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2bb6c3-8235-40ae-9bde-6c1cf5fde3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
